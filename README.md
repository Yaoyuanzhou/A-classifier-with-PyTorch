# ğŸ€ åŸºäºTorchvisionä¸­çš„ç»å…¸æ¨¡å‹è°ƒç”¨ :yum:


**This code calls the models in Torchvision, and the classification network topic framework is derived from Torchvision.**
åŸºäºtorchvisionä¸­çš„æ¨¡å‹å†™äº†çš„è°ƒç”¨æ¥å£ï¼Œå¯¹äºåˆšå¼€å§‹å­¦ä¹ æ·±åº¦å­¦ä¹ çš„äººå¯ä»¥ä»¥æ­¤æ¥è·‘å„ä¸ªç»å…¸æ¨¡å‹çš„demoï¼Œå¦‚éœ€äº†è§£å…·ä½“ç½‘ç»œæ¡†æ¶å’Œä»£ç ç»†èŠ‚å¯ä»¥æ·±å…¥torchvisionæºç ã€‚ä¾‹å¦‚ä»¥ä¸‹ç»å…¸çš„åˆ†ç±»æ¨¡å‹å’Œåˆ†å‰²æ¨¡å‹éƒ½å¯ä»¥è°ƒç”¨ï¼š
```python
from .alexnet import *
from .resnet import *
from .vgg import *
from .squeezenet import *
from .inception import *
from .densenet import *
from .googlenet import *
from .mobilenet import *
from .mnasnet import *
from .shufflenetv2 import *
from . import segmentation
from . import detection
from . import video
```
![image info](image/classifier.png) 
```python
#Several classification frameworks are available
AlexNetã€densenet121ã€densenet169ã€densenet201ã€densenet161ã€GoogLeNetã€Inception3ã€mnasnet0_5ã€mnasnet0_75ã€mnasnet1_0ã€mnasnet1_3ã€MobileNetV2ã€resnet18ã€resnet34ã€resnet50ã€resnet101ã€resnet152ã€resnext50_32x4dã€resnext101_32x8dã€wide_resnet50_2ã€wide_resnet101_2ã€vgg11ã€vgg13ã€vgg16ã€vgg19ã€vgg11_bnã€vgg13_bnã€vgg16_bnã€vgg19_bn...........
```
*The above is the classic network framework available within the models, and only for the classification networks within.This code is can take transfer learning , download the ImageNet pre trained initial model and then transfer learning  in your code, and can be frozen convolution training only full connection layer, or global training, we only use the convolution of the classic network layer, and then the convolution results set on our lightweight classifierï¼Œ*


## :rainbow: Train on our datasets
We used this classifier to predict the gender of the chicken, and we used vgg16,vgg16_bn,vgg19,vgg19_bn,resnet18,resnet34ã€densenet101 made a comparisonã€‚You can get our dataset [here](https://drive.google.com/open?id=1eGq8dWGL0I3rW2B9eJ_casH0_D3x7R73 "dataset")
æˆ‘ä»¬ç”¨çš„æ˜¯è‡ªå·±åˆ¶ä½œçš„ä¸€ä¸ªé¸¡æ€§åˆ«åˆ†ç±»æ•°æ®é›†ï¼Œå¯ä»¥åœ¨[è°·æ­Œäº‘ç›˜](https://drive.google.com/open?id=1eGq8dWGL0I3rW2B9eJ_casH0_D3x7R73 "dataset")ä¸­è·å¾—æˆ‘ä»¬çš„æ•°æ®ï¼Œ

**Some sample images from Our dataset:**
![image info](image/dataset.jpg) 

## :star2: Train on Custom Dataset
å¦‚æœéœ€è¦åœ¨ä½ è‡ªå·±çš„æ•°æ®é›†ä¸Šè¿è¡Œï¼Œåªéœ€è¦å¦‚ä¸‹é¢çš„ç»“æ„å­˜æ”¾å³å¯ï¼Œnä»£è¡¨ä½ æ˜¯å‡ åˆ†ç±»ä»»åŠ¡ï¼Œä¾‹å¦‚trainä¸‹label_1ä¸‹æ˜¯å­˜æ”¾ç¬¬ä¸€ä¸ªç±»åˆ«çš„æ‰€æœ‰è®­ç»ƒå›¾åƒï¼Œä»¥æ­¤ç±»æ¨
```
-your datasets
 |--train
 |   |--label_1
 |   |--label_2
 |   |--label_n
 |--test or Val
     |--label_1
     |--label_2
     |--label_n
```
Your data set needs to look like the file structure above.And if you're not dichotomous, change the last output dimension from 2 to nã€‚
 **Then execute the following command**
 
 `python train.py --data_directory=your dataset --arch=vgg16`
 data_directoryç”¨ä»¥æŒ‡æ˜ä½ çš„æ•°æ®é›†è·¯å¾„åœ°å€ï¼Œarchä¸ºé€‰æ‹©çš„æ¨¡å‹å
if you want to train on resnet or densenet and other, you can change the --arch=vgg16 to --arch=resnet34 or -- arch=densenet101 or other
## Visualization of Training Process
Use tensorboard for visualization. After training, you can enter the following command for visualization.

**Then visit the page that pops up on the command line,the following image will appear**

`tensorboard --logdirs=logs`

![image info](image/vis.jpg)

**Visit the above page and download the corresponding CSV, then plot the training process according to csv_plot.pyï¼š**
![image info](image/Plot.jpg)
**You can adjust the parameters to make the training process more beautiful**
